{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b40c1326-ba40-42e1-94a2-bbb10a94dd12",
   "metadata": {},
   "source": [
    "# Keypoint Classification for Hand Gesture Recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a86ef4e2",
   "metadata": {},
   "source": [
    "https://github.com/kinivi/tello-gesture-control#Gesture-control\n",
    "\n",
    "https://github.com/Kazuhito00/hand-gesture-recognition-using-mediapipe/tree/main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3f15996-b51b-409f-b642-935c4d1b1528",
   "metadata": {},
   "source": [
    "## Import Necessary Dependacies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "60a7faff-31a3-4a18-a43d-bd13c0b8a06b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (864999259.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[387], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    import tensorflow-gpu\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import os \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97d67a49-6eee-49f6-9cd6-23e66a8325d2",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "08b138e5-7ee5-46a1-8960-ca9caf6e8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_dataset = 'data/keypoint.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier.hdf5'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d92de116-c5e9-4542-881e-298a844d8d9b",
   "metadata": {},
   "source": [
    "## Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "e8ce647a-e36f-423d-92e2-ac4f61ba3515",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(keypoint_dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))\n",
    "y_dataset = np.loadtxt(keypoint_dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a814def-3812-4f44-8f85-6296bd01850f",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "0a303c3f-5687-46b6-94ae-ab379ef8dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "b03326de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1522, 1572], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classes count\n",
    "counts = np.unique(y_dataset, return_counts=True)\n",
    "df = pd.DataFrame(counts)\n",
    "df.T.plot(kind=\"bar\", stacked=True)\n",
    "print(counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fe16a26-f52d-4e88-b568-635067506129",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "2ce5d342-1802-49b6-b5d1-dcfa859c63f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "94ba9bd0-ffae-4f19-a8fd-4a3687ae7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.0),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.0),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.0),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "f361270c-0682-4d7e-9bcb-27b8d4a59ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_80 (Dropout)        (None, 42)                0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 32)                1376      \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,994\n",
      "Trainable params: 2,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "7f51fc8a-ec4f-4ecf-9224-f0814e5c215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Checkpoints\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# Early Stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "624a3419-b317-432f-911b-a07d9e3bf994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "790c3b71-4603-4a00-b4c8-68993205bb3f",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "cab54a32-bdd0-403a-a958-5b89ea02e1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/550\n",
      " 1/19 [>.............................] - ETA: 9s - loss: 0.7034 - accuracy: 0.4688\n",
      "Epoch 1: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 0.6546 - accuracy: 0.6379 - val_loss: 0.5955 - val_accuracy: 0.8488\n",
      "Epoch 2/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.6004 - accuracy: 0.8438\n",
      "Epoch 2: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5364 - accuracy: 0.8974 - val_loss: 0.4555 - val_accuracy: 0.9302\n",
      "Epoch 3/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.4467 - accuracy: 0.9062\n",
      "Epoch 3: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.9198 - val_loss: 0.2939 - val_accuracy: 0.9341\n",
      "Epoch 4/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.3127 - accuracy: 0.9062\n",
      "Epoch 4: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2384 - accuracy: 0.9392 - val_loss: 0.1806 - val_accuracy: 0.9548\n",
      "Epoch 5/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.1811 - accuracy: 0.9609\n",
      "Epoch 5: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.1527 - accuracy: 0.9608 - val_loss: 0.1176 - val_accuracy: 0.9755\n",
      "Epoch 6/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.1256 - accuracy: 0.9688\n",
      "Epoch 6: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9784 - val_loss: 0.0841 - val_accuracy: 0.9845\n",
      "Epoch 7/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.1101 - accuracy: 0.9766\n",
      "Epoch 7: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.9832 - val_loss: 0.0662 - val_accuracy: 0.9871\n",
      "Epoch 8/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0727 - accuracy: 0.9844\n",
      "Epoch 8: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.9853 - val_loss: 0.0561 - val_accuracy: 0.9871\n",
      "Epoch 9/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0776 - accuracy: 0.9766\n",
      "Epoch 9: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9862 - val_loss: 0.0488 - val_accuracy: 0.9884\n",
      "Epoch 10/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 10: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9875 - val_loss: 0.0485 - val_accuracy: 0.9884\n",
      "Epoch 11/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0447 - accuracy: 0.9922\n",
      "Epoch 11: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9888 - val_loss: 0.0387 - val_accuracy: 0.9910\n",
      "Epoch 12/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 12: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 0.0398 - val_accuracy: 0.9922\n",
      "Epoch 13/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 13: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0354 - accuracy: 0.9875 - val_loss: 0.0325 - val_accuracy: 0.9922\n",
      "Epoch 14/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0259 - accuracy: 0.9922\n",
      "Epoch 14: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.0304 - val_accuracy: 0.9935\n",
      "Epoch 15/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0142 - accuracy: 0.9922\n",
      "Epoch 15: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9914 - val_loss: 0.0297 - val_accuracy: 0.9935\n",
      "Epoch 16/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 16: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.0287 - val_accuracy: 0.9948\n",
      "Epoch 17/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0294 - accuracy: 0.9922\n",
      "Epoch 17: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.0278 - val_accuracy: 0.9948\n",
      "Epoch 18/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0124 - accuracy: 0.9922\n",
      "Epoch 18: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.0233 - val_accuracy: 0.9948\n",
      "Epoch 19/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 19: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0229 - val_accuracy: 0.9948\n",
      "Epoch 20/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0131 - accuracy: 0.9922\n",
      "Epoch 20: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.0216 - val_accuracy: 0.9948\n",
      "Epoch 21/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0240 - accuracy: 0.9922\n",
      "Epoch 21: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.0199 - val_accuracy: 0.9948\n",
      "Epoch 22/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 22: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.0196 - val_accuracy: 0.9948\n",
      "Epoch 23/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 23: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0187 - val_accuracy: 0.9948\n",
      "Epoch 24/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 24: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.0185 - val_accuracy: 0.9948\n",
      "Epoch 25/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 25: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0171 - val_accuracy: 0.9948\n",
      "Epoch 26/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 26: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.0179 - val_accuracy: 0.9948\n",
      "Epoch 27/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 27: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.0173 - val_accuracy: 0.9948\n",
      "Epoch 28/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 28: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0168 - val_accuracy: 0.9948\n",
      "Epoch 29/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0081 - accuracy: 0.9922\n",
      "Epoch 29: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0154 - val_accuracy: 0.9961\n",
      "Epoch 30/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 30: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.0164 - val_accuracy: 0.9961\n",
      "Epoch 31/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0117 - accuracy: 0.9922\n",
      "Epoch 31: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0139 - val_accuracy: 0.9961\n",
      "Epoch 32/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 32: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0172 - val_accuracy: 0.9948\n",
      "Epoch 33/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0159 - accuracy: 0.9922\n",
      "Epoch 33: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0148 - val_accuracy: 0.9961\n",
      "Epoch 34/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 34: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0138 - val_accuracy: 0.9961\n",
      "Epoch 35/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 35: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0135 - val_accuracy: 0.9987\n",
      "Epoch 36/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 36: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0137 - val_accuracy: 0.9961\n",
      "Epoch 37/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 37: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0138 - val_accuracy: 0.9961\n",
      "Epoch 38/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 38: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0128 - val_accuracy: 0.9987\n",
      "Epoch 39/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 39: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0124 - val_accuracy: 0.9987\n",
      "Epoch 40/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 40: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0129 - val_accuracy: 0.9987\n",
      "Epoch 41/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 41: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0129 - val_accuracy: 0.9974\n",
      "Epoch 42/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 8.9746e-04 - accuracy: 1.0000\n",
      "Epoch 42: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0130 - val_accuracy: 0.9974\n",
      "Epoch 43/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 43: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0138 - val_accuracy: 0.9987\n",
      "Epoch 44/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 2.7859e-04 - accuracy: 1.0000\n",
      "Epoch 44: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0120 - val_accuracy: 0.9987\n",
      "Epoch 45/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 45: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9987\n",
      "Epoch 46/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 46: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0129 - val_accuracy: 0.9987\n",
      "Epoch 47/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 9.8002e-04 - accuracy: 1.0000\n",
      "Epoch 47: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9987\n",
      "Epoch 48/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 6.6284e-04 - accuracy: 1.0000\n",
      "Epoch 48: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0122 - val_accuracy: 0.9987\n",
      "Epoch 49/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 49: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0125 - val_accuracy: 0.9987\n",
      "Epoch 50/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 7.4249e-04 - accuracy: 1.0000\n",
      "Epoch 50: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "Epoch 51/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 51: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0136 - val_accuracy: 0.9987\n",
      "Epoch 52/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 52: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0126 - val_accuracy: 0.9987\n",
      "Epoch 53/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 53: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.0123 - val_accuracy: 0.9987\n",
      "Epoch 54/550\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 5.4707e-04 - accuracy: 1.0000\n",
      "Epoch 54: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9974\n",
      "Epoch 54: early stopping\n"
     ]
    }
   ],
   "source": [
    "# save model to plot a curve of accuracy and loss after training\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=550,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "378218f9-ed39-44cb-bd46-01b9f5634d7e",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20f65f65-009c-4efa-8b7d-d325bd69be97",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "5a6b32b9-a69b-4c55-b2de-6d675a8656cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       372\n",
      "           1       1.00      1.00      1.00       402\n",
      "\n",
      "    accuracy                           1.00       774\n",
      "   macro avg       1.00      1.00      1.00       774\n",
      "weighted avg       1.00      1.00      1.00       774\n",
      "\n",
      "[[372   0]\n",
      " [  2 400]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed787056-a88b-4e99-b56f-caa76e818eaa",
   "metadata": {},
   "source": [
    "## TF-Lite Deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbe48b07-7145-4ec4-831a-550635bd619a",
   "metadata": {},
   "source": [
    "#### Save the model (inference only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "ef7dfc1e-2179-4ed3-881c-f85c0beb63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b06ebf22-b13f-49be-85a1-58238cfd335c",
   "metadata": {},
   "source": [
    "#### Model Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "42f1cc08-e835-4f34-b3ce-240f2e2bcab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\calgr\\AppData\\Local\\Temp\\tmpd5j_k_xp\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\calgr\\AppData\\Local\\Temp\\tmpd5j_k_xp\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Quantization\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0318a85b-9ccf-423e-b654-a89aaa0b17c2",
   "metadata": {},
   "source": [
    "### Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b778ea7c-26d8-4353-8912-867842447cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "0e0fe364-6b03-466f-bb64-ef59d525991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input, Output Tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "85a6f6f8-da5f-4641-bb78-a64ba2e52644",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccd28c7d-a463-4601-a0da-fa149e448592",
   "metadata": {},
   "source": [
    "### Inference Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "21760d85-870d-4550-91dd-6f8e611429c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "a20bee9c-b9e9-450e-999d-ae86f2b7f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.1402933e-07 9.9999964e-01]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9580574d",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "b7980260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !zip -r model.zip keypoint_classifier\n",
    "os.system(\"zip -r model.zip keypoint_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a895657d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
